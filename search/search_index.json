{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"GenIR Reading Group","text":"<p>\u6b22\u8fce\u6765\u5230\u6211\u4eec\u7684 Generative Information Retrieval \u9605\u8bfb\u7b14\u8bb0\u7f51\u7ad9\uff01</p> <p>\u6211\u4eec\u4f1a\u5728\u8fd9\u91cc\u6574\u7406\uff1a - \u6309\u4e3b\u9898\u5206\u7c7b\u7684 GenIR \u8bba\u6587 - \u6bcf\u7bc7\u8bba\u6587\u7684 Paper + Code \u94fe\u63a5 - \u7b80\u77ed\u7684\u4e00\u53e5\u8bdd\u603b\u7ed3 - Roadmap\uff08\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\u56fe\uff09  </p> <p>\u540e\u7eed\u6211\u4eec\u4f1a\u7ee7\u7eed\u8865\u5145\u5185\u5bb9\u3002</p>"},{"location":"document_retrieval/papers/","title":"Papers: Document Retrieval","text":"<p>This page organizes Generative Document Retrieval papers by their core innovation. For each paper, we list the title, link, a short 1\u20132 sentence summary, and tags. This categorization avoids duplication across method components and groups papers by their main intellectual contribution.</p>"},{"location":"document_retrieval/papers/#a-id-space-indexing-innovations","title":"\ud83d\udd37 A. ID Space &amp; Indexing Innovations","text":""},{"location":"document_retrieval/papers/#asi-autoregressive-search-index-iclr-2023","title":"ASI \u2013 Autoregressive Search Index (ICLR 2023)","text":"<p>\ud83d\udd17 paper Summary: Introduces hierarchical document IDs organized as a multi-level tree to improve retrieval control and semantic structuring. Tags: <code>hierarchical-id</code>, <code>indexing</code>, <code>tree-structure</code></p>"},{"location":"document_retrieval/papers/#seater-2023","title":"SEATER (2023)","text":"<p>\ud83d\udd17 paper Summary: Decomposes GR errors and proposes structured tree IDs to reduce ambiguity during ID generation. Tags: <code>structured-id</code>, <code>error-analysis</code></p>"},{"location":"document_retrieval/papers/#dci-discriminative-contrastive-indexing-sigir-2025","title":"DCI \u2013 Discriminative Contrastive Indexing (SIGIR 2025)","text":"<p>\ud83d\udd17 paper (placeholder) Summary: Employs groupwise contrastive learning to produce more discriminative and semantically separated document IDs. Tags: <code>contrastive-learning</code>, <code>id-learning</code>, <code>indexing</code></p>"},{"location":"document_retrieval/papers/#corpus-aligned-id-initialization-2024","title":"Corpus-Aligned ID Initialization (2024)","text":"<p>\ud83d\udd17 paper Summary: Generates pseudo-queries from corpus text to create corpus-aligned initial IDs that better match semantic distributions. Tags: <code>id-initialization</code>, <code>query-synthesis</code></p>"},{"location":"document_retrieval/papers/#b-decoding-inference-innovations","title":"\ud83d\udd37 B. Decoding &amp; Inference Innovations","text":""},{"location":"document_retrieval/papers/#gr2-guided-decoding-for-generative-retrieval-iclr-2023","title":"GR2 \u2013 Guided Decoding for Generative Retrieval (ICLR 2023)","text":"<p>\ud83d\udd17 paper Summary: Adds constraints and guidance to the decoding process to improve the accuracy and determinism of ID generation. Tags: <code>guided-decoding</code>, <code>constraint</code></p>"},{"location":"document_retrieval/papers/#reasongr-multi-step-reasoning-for-gr-neurips-2024","title":"ReasonGR \u2013 Multi-Step Reasoning for GR (NeurIPS 2024)","text":"<p>\ud83d\udd17 paper Summary: Introduces multi-hop reasoning within decoding, enabling more accurate ID predictions for ambiguous or complex queries. Tags: <code>reasoning</code>, <code>multihop</code>, <code>complex-query</code></p>"},{"location":"document_retrieval/papers/#cgbs-decoding-2025","title":"CGBS Decoding (2025)","text":"<p>\ud83d\udd17 paper (placeholder) Summary: Uses query\u2013cover alignment signals and constrained decoding to incorporate visual information into ID generation. Tags: <code>cover-aware</code>, <code>cross-modal-decoding</code>, <code>constraint</code></p>"},{"location":"document_retrieval/papers/#c-model-architecture-innovations","title":"\ud83d\udd37 C. Model Architecture Innovations","text":""},{"location":"document_retrieval/papers/#genre-2020","title":"GENRE (2020)","text":"<p>\ud83d\udd17 paper \u00b7 code Summary: Early generative retrieval using seq2seq generation over entity names; foundational to Generative IR. Tags: <code>seq2seq</code>, <code>entity-retrieval</code></p>"},{"location":"document_retrieval/papers/#t5-for-retrieval-2021","title":"T5 for Retrieval (2021)","text":"<p>\ud83d\udd17 paper Summary: Shows that encoder\u2013decoder LMs can be fine-tuned to directly generate document IDs. Tags: <code>t5</code>, <code>encoder-decoder</code></p>"},{"location":"document_retrieval/papers/#nova-unified-to-specialized-generative-framework-aaai-2026","title":"NOVA \u2013 Unified-to-Specialized Generative Framework (AAAI 2026)","text":"<p>\ud83d\udd17 paper (placeholder) Summary: Proposes a multi-view architecture combining a unified encoder with specialized decoders for cross-modal and text-only retrieval. Tags: <code>multi-view</code>, <code>specialized-decoder</code>, <code>architecture</code></p>"},{"location":"document_retrieval/papers/#d-training-paradigms-learning-signals","title":"\ud83d\udd37 D. Training Paradigms &amp; Learning Signals","text":""},{"location":"document_retrieval/papers/#bm25-labeled-gr-training-2023","title":"BM25-Labeled GR Training (2023)","text":"<p>\ud83d\udd17 paper Summary: Supervises GR using BM25-based pseudo labels, enabling training without annotated relevance data. Tags: <code>pseudo-label</code>, <code>weak-supervision</code></p>"},{"location":"document_retrieval/papers/#synthetic-query-learning-2024","title":"Synthetic Query Learning (2024)","text":"<p>\ud83d\udd17 paper (placeholder) Summary: Uses LLMs to generate synthetic queries and trains GR on the synthetic ID mappings. Tags: <code>synthetic-data</code>, <code>pretraining</code></p>"},{"location":"document_retrieval/papers/#contrastive-hybrid-training-2025","title":"Contrastive Hybrid Training (2025)","text":"<p>\ud83d\udd17 paper (placeholder) Summary: Combines generative objectives with contrastive docID supervision for more stable and discriminative GR training. Tags: <code>hybrid-training</code>, <code>contrastive</code></p>"}]}