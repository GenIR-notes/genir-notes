# Resources for Getting Started with Generative IR

This page provides a curated set of **entry-level resources** for students and researchers who want to quickly understand and start working on **Generative Information Retrieval (GenIR)**, **Generative Recommendation (GenRec)**, and **Multimodal Generative Retrieval**.

It includes tutorials, starter code, datasets, beginner-friendly papers, and tools.

---

## ðŸ”¹ 1. What is Generative IR?

Generative IR treats retrieval as a **sequence generation problem**.  
Instead of scoring documents (dense/sparse retrieval), a model **directly generates document identifiers (DocIDs)** conditioned on a query.

This paradigm enables:
- flexible reasoning  
- multimodal integration  
- unifying retrieval with generation  
- direct indexing via generative models

---

## ðŸ”¹ 2. Tutorials & Surveys

**Our tutorial (recommended starting point):**  
ðŸ‘‰ [GenIR Tutorial](your-link-here)

**Other helpful materials:**
- *Generative Search and Retrieval (2024)* â€” overview slides  
- *The rise of generative retrieval models (2023)* â€” survey  
- *SIGIR/ECIR tutorial slides (if any available public)*  

You may also find NeurIPS and ICLR spotlight videos helpful for high-level intuition.

---

## ðŸ”¹ 3. Starter Code Repositories

Begin with small, runnable implementations:

- **Minimal T5-based Generative Retriever**  
  https://github.com/example/t5-simple-genir

- **GR2-style constrained decoding demo**  
  https://github.com/example/gr2-decoding-demo

- **Prefix-tree decoding example**  
  https://github.com/example/prefix-tree-search

- **BM25-labeled GR Training**  
  A simple script: generate docIDs from BM25 labels and train a seq2seq model.

Recommended starting exercise:  
ðŸ‘‰ Train a small T5 model to generate document IDs on a tiny dataset.

---

## ðŸ”¹ 4. Datasets for Experiments

### Text Retrieval
- **MS MARCO (Passage / Document)**  
- **BEIR** (benchmark suite)  
- **Natural Questions (NQ)**  
- **MIRACL**

### Multimodal Retrieval
- **MS-COCO**  
- **Flickr30K**  
- **BookCover30K**  
- **WhatsThatBook**  

### For Teaching / Prototyping
- Small Wikipedia slices  
- QA subsets  
- Your own prepared toy datasets

---

## ðŸ”¹ 5. Beginner start reading recommendations

**Recommended Entry Path (Beginner â† Intermediate â† Modern):**

1. **GENRE (2020)** â€” first works on generative retrieval  
2. **T5 for Retrieval (2021)** â€” simple baseline  
3. **ASI (ICLR 2023)** â€” introduces hierarchical DocIDs  
4. **GR2 (ICLR 2023)** â€” constrained decoding  
5. **ReasonGR (NeurIPS 2024)** â€” reasoning-based decoding  
6. **DCI (SIGIR 2025)** â€” discriminative indexing  
7. **NOVA (AAAI 2026)** â€” unified-to-specialized architecture

Reading these gives a complete understanding of the fieldâ€™s evolution.

---

## ðŸ”¹ 6. Tools & Practical Components

Helpful elements commonly used in GR systems:

- **Prefix tree builder**
- **ID quantization / clustering**
- **DocID templates (hierarchical IDs)**
- **Synthetic query generators**
- **Constrained beam search tools**
- **Visual-text encoders (for multimodal work)**

We recommend building a minimal pipeline:
> query â†’ encoder â†’ decoder â†’ docID â†’ matching â†’ evaluation

to get hands-on experience.

---

## ðŸ”¹ 7. Extra: Joining the Community

- SIGIR paper reading groups  
- Open-source GR communities  
- Relevant GitHub organizations and curated lists  
- Discord/Slack groups (if applicable)

---

*Feel free to suggest new resources â€” this page is intended to grow with the community.*
